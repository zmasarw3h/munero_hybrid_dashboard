# Munero AI Platform - Environment Configuration
# Copy this file to .env and adjust values as needed

# Application
# Hosted/production deployments should keep DEBUG disabled.
DEBUG=False

# WARNING: When enabled, logs may include sensitive user prompts/responses.
# Keep this disabled in hosted/production deployments.
DEBUG_LOG_PROMPTS=False

# Database (automatically set to ../data/munero.sqlite)
# For hosted Postgres/Supabase, set DATABASE_URL to a least-privilege read-only login (e.g. munero_app).
# DATABASE_URL=postgresql+psycopg://munero_app:<PASSWORD>@db.<PROJECT_REF>.supabase.co:5432/postgres?sslmode=require
# DB_FILE=/path/to/custom/database.sqlite
# Postgres per-statement timeout (milliseconds). Applied via connection options.
# DB_STATEMENT_TIMEOUT_MS=30000
# When False, DB failures raise and surface as API errors (recommended for hosted).
# DB_RETURN_EMPTY_ON_ERROR=False

# LLM Configuration (Hosted API, default provider: Gemini)
LLM_PROVIDER=gemini
# Server-side only. Do NOT expose to the frontend.
# LLM_API_KEY=your_api_key_here
# Gemini-specific aliases supported: GEMINI_API_KEY / GOOGLE_API_KEY
LLM_MODEL=gemini-2.5-flash
LLM_BASE_URL=https://generativelanguage.googleapis.com/v1beta
LLM_TEMPERATURE=0.0
LLM_TIMEOUT=60
LLM_MAX_OUTPUT_TOKENS=512
LLM_RETRIES=2
SQL_TIMEOUT=30
# Optional: auto-repair SQL once when execution fails (adds latency/cost on failures).
# Set to 0 to disable.
LLM_SQL_REPAIR_MAX_ATTEMPTS=1
# Optional: fallback model used only for SQL generation retries + SQL repair prompts.
# Recommended to keep LLM_MODEL fast/cheap and set this to a stronger model for edge cases.
# LLM_FALLBACK_MODEL=<stronger-model-name>
# Only used on fallback/retry/repair calls (ignored on the primary call).
LLM_FALLBACK_MAX_OUTPUT_TOKENS=1024
# Total attempts for SQL generation (initial + retries). Default 2 == 1 retry.
LLM_SQL_GENERATION_MAX_ATTEMPTS=2

# Query Settings
MAX_DISPLAY_ROWS=1000
SHOW_SQL_DEFAULT=True

# Chat export hardening (recommended for hosted deployments)
# When set, /api/chat/export-csv requires a signed short-lived export token.
# EXPORT_SIGNING_SECRET=change-me
# EXPORT_TOKEN_TTL_S=900

# CORS Origins (comma-separated)
# Accepts either:
# - Comma-separated: https://your-app.vercel.app,http://localhost:3000
# - JSON list (recommended): ["https://your-app.vercel.app","http://localhost:3000"]
# Notes:
# - No trailing slashes (origins look like https://host, not https://host/)
# - Avoid wrapping the whole value in extra quotes in hosting dashboards
# CORS_ORIGINS=["https://your-app.vercel.app","http://localhost:3000"]
#
# Optional: allow dynamic origins via regex (Starlette CORSMiddleware allow_origin_regex).
# This is useful for Vercel preview deployments where the subdomain changes per build.
# Example (allows production + previews for this project):
# CORS_ORIGINS_REGEX=^https://munero-hybrid-dashboard(-[a-z0-9-]+)?[.]vercel[.]app$

# SmartRender Visualization Settings
MAX_CHART_CATEGORIES=15
LONG_LABEL_THRESHOLD=20
PIE_CHART_MAX=8
